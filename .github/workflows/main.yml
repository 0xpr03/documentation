name: Deploy to staging & run scraper
on:
  push:
    branches:
      - main
      - new-docs-content

jobs:
  deploy-to-staging:
    runs-on: ubuntu-22.04
    steps:
      - name: Ping the deployment hook
        id: ping_hook
        run: |
          response="$(curl -X POST https://api.vercel.com/v1/integrations/deploy/prj_hqVc8cCGcLtlNKTtjDy37umkXlKp/hNXqWEPK1U)" 
          data="$(jq -r ".job.id" <<< "$response")"
          echo "url=website-$data-meili.vercel.app" >> $GITHUB_ENV

      - uses: UnlyEd/github-action-await-vercel@v1.2.39
        id: await_vercel
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
        with:
          deployment-url: ${{ env.url }}
          timeout: 180

      - name: Display deployment status
        run: "echo The deployment at ${{ fromJson(steps.await-vercel.outputs.deploymentDetails).url }} is ${{ fromJson(steps.await-vercel.outputs.deploymentDetails).readyState }}"

  scrape-docs:
    needs: deploy-to-staging
    runs-on: ubuntu-20.04
    name: scrape and push content on Meilisearch instance
    steps:
      - uses: actions/checkout@v3
      - name: Run docs-scraper
        env:
          HOST_URL: ${{ secrets.MEILISEARCH_HOST_URL }}
          API_KEY: ${{ secrets.MEILISEARCH_API_KEY }}
          CONFIG_FILE_PATH: ${{ github.workspace }}/docs-scraper.config.json
        run: |
          docker run -t --rm \
            -e MEILISEARCH_HOST_URL=$HOST_URL \
            -e MEILISEARCH_API_KEY=$API_KEY \
            -v $CONFIG_FILE_PATH:/docs-scraper/config.json \
            getmeili/docs-scraper:v0.12.8 pipenv run ./docs_scraper config.json